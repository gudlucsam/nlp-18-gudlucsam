{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import csv\n",
    "import math\n",
    "from utility_functions import *\n",
    "from component_functions import *\n",
    "\n",
    "\n",
    "def classifier(review, cls, vblry):\n",
    "    \"\"\"\n",
    "        Calculates the likelihood component of a review.\n",
    "    \"\"\"\n",
    "    \n",
    "    # sanitize review\n",
    "    for ch in [',', ';', '.', '\"', '!', '(', ')', ':', '/', \"-\", '\\\\' ]:\n",
    "        if ch in review:\n",
    "            review = review.replace(ch, ' ')\n",
    "    lst = list(review.split())\n",
    "    \n",
    "    likelihood = 1\n",
    "    for word in lst:\n",
    "        likelihood*=likelihoodOfWordInCls(word, cls)\n",
    "    \n",
    "    return likelihood\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def naive_bayes_classifier(testdoc):\n",
    "    \"\"\"\n",
    "        This function takes a testdoc.txt file containing a several sentences each sentence representing a review.\n",
    "        and returns a result.txt file containing assigned categories for each review, whether a positive review or negative.\n",
    "    \"\"\"\n",
    "    \n",
    "    # source of dataset\n",
    "    vocabulary = '../sentiment-labelled-sentences/mainDataset.csv'\n",
    "    \n",
    "    # classes used\n",
    "    cls = [0, 1]\n",
    "    \n",
    "    \n",
    "    with open(testdoc, 'r') as f1, open('../sentiment-labelled-sentences/result.txt', 'w') as f2:\n",
    "        for review in f1:\n",
    "            #categoried reviews\n",
    "            prob = []\n",
    "            for c in cls:\n",
    "                # calculating prior probability\n",
    "                prior_prob = priorProb(vocabulary, c)\n",
    "                # calculating likelihood\n",
    "                likelihoodOfReview = classifier(review, c, vocabulary)\n",
    "                # find the probability of review in a class\n",
    "                prob_of_review_in_cls = likelihoodOfReview * prior_prob\n",
    "                # append to list\n",
    "                prob.append(prob_of_review_in_cls)\n",
    "                \n",
    "            # compare and select category of review\n",
    "            print(prob)\n",
    "            f2.write(str(prob.index(max(prob))) + '\\n')\n",
    "            \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23098"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing countWrdsOfVocInCls function in component_functions.py\n",
    "\n",
    "countWrdsOfVocInCls('../sentiment-labelled-sentences/mainDataset.csv', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3648792186987904"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing likelihoodOfWordInCls in component_functions.py\n",
    "\n",
    "likelihoodOfWordInCls('the', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6020599913279624"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing priorProb function from component_functions.py\n",
    "\n",
    "priorProb('../sentiment-labelled-sentences/mainDataset.csv', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.4964342257531"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing function that calculates likehood of a review in a class\n",
    "classifier('young man.', 1, '../sentiment-labelled-sentences/mainDataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4372900.770062734, -5795183.200693902]\n",
      "[-100635717.64327317, -220383580.5373181]\n",
      "[-10941404987333.73, -28329680281108.793]\n",
      "[-3157.2190032027934, -4026.406134813517]\n",
      "[1833276867.5407126, 1236713133.260967]\n"
     ]
    }
   ],
   "source": [
    "# Testing the naive bayes classifier\n",
    "naive_bayes_classifier('../sentiment-labelled-sentences/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
